# ğŸ¤– Ambit AI - Advanced Voice Assistant

Next-generation AI assistant with professional WebRTC audio, multiple voice personas, and customizable behavior.

## âœ¨ What's New

### ğŸ¨ Enhanced Audio Visualizer
- **Interactive real-time waveform** with smooth animations
- **Professional gradient effects** that respond to voice activity
- **Visual feedback indicators** for speaking, processing, and AI responses
- **Refined UI elements** with modern glassmorphism design

### ğŸ¤ Multiple Voice Personas
Choose from 8 unique AI voices:
- **Kyle (Default)** - Natural, conversational voice
- **Deep Monster** - Dark and intimidating presence
- **Mad Scientist** - Eccentric and brilliant personality  
- **Anxious Nerd** - Nervous but highly intelligent
- **Cowboy** - Rugged Western charm
- **Old Wizard** - Wise and mystical sage
- **Anon** - Anonymous, neutral voice
- **Funny Nerd** - Quirky and humorous character
- **Custom Voice** - Use your own ElevenLabs voice ID

### ğŸ› ï¸ Advanced Configuration
- **Custom AI Instructions** - Personalize Ambit's behavior and responses
- **API Key Override** - Use your own OpenAI/ElevenLabs keys
- **Persistent Settings** - All preferences saved locally
- **Real-time Configuration** - Changes apply instantly

## ğŸš€ Features

- **ğŸŒ Modern Web Interface** - Beautiful, responsive design with enhanced UI elements
- **ğŸ¤ Professional Audio** - WebRTC echo cancellation, noise suppression, and auto gain control
- **ğŸ”Š Real-time Voice** - Enhanced audio visualization with interactive feedback
- **ğŸ‘¥ Multiple Personas** - 8 unique voice characters plus custom voice support
- **ğŸ“ Custom Instructions** - Tailor AI behavior to your specific needs
- **âš™ï¸ Advanced Settings** - Full control over AI parameters and API keys
- **ğŸ’¾ Local Storage** - Settings persist between sessions
- **ğŸ“± Cross-Platform** - Works on any device with a modern browser
- **ğŸš€ Zero Installation** - No complex dependencies or environment issues

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure Environment
```bash
cp .env.example .env
# Edit .env with your API keys:
# OPENAI_API_KEY=your_openai_key_here
# ELEVENLABS_API_KEY=your_elevenlabs_key_here
# ELEVENLABS_VOICE_ID=your_voice_id_here
```

### 3. Start the Backend
```bash
python ambit_backend.py
```

### 4. Open the Web Interface
Open `ambit_web_gui.html` in your browser.

## ğŸ¤ Using Voice Features

1. **Connect** - Click "Start Conversation"
2. **Grant Permission** - Allow microphone access when prompted
3. **Choose Voice** - Select from preset voices or use custom voice ID
4. **Customize** - Add custom instructions to modify behavior
5. **Talk** - Speak naturally with professional echo cancellation

## ğŸ”§ Configuration Options

### Voice Settings
- **Preset Voices** - Choose from 8 unique character voices
- **Custom Voice ID** - Use any ElevenLabs voice ID
- **Voice Preview** - Each voice includes personality description

### Advanced Settings
- **Custom Instructions** - Add specific behavior modifications
  - Example: "Always respond in a cheerful tone"
  - Example: "Focus on technical details when explaining"
- **API Key Override** - Use personal API keys instead of defaults
- **Max Tokens** - Control response length (50-500 tokens)

## ğŸ› ï¸ Architecture

### Core Components

- **`ambit_web_gui.html`** - Enhanced web interface with interactive visualizer
- **`ambit_backend.py`** - Unified WebSocket server with AI integration
- **`ambit_instructions.py`** - Base AI personality and behavior
- **`style.css`** - Modern styling with glassmorphism effects

### Enhanced Audio Pipeline

```
Browser Microphone â†’ WebRTC AEC â†’ Enhanced Visualizer â†’ WebSocket â†’ 
â†’ Python Backend â†’ Custom Instructions â†’ OpenAI â†’ Selected Voice â†’ 
â†’ ElevenLabs â†’ Browser Audio with Visual Feedback
```

### Voice Processing Flow

1. **Input Capture** - WebRTC captures audio with echo cancellation
2. **Visual Feedback** - Real-time waveform shows audio levels
3. **VAD Processing** - Silero VAD detects speech segments
4. **Transcription** - Audio converted to text in real-time
5. **AI Processing** - OpenAI processes with custom instructions
6. **Voice Synthesis** - ElevenLabs generates with selected voice
7. **Playback** - Audio plays with synchronized visual feedback

## ğŸ¨ UI Enhancements

- **Glassmorphism Design** - Modern frosted glass effects
- **Smooth Animations** - 60fps visualizer with gradient effects
- **Responsive Layout** - Adapts to any screen size
- **Visual States** - Different colors for listening/processing/speaking
- **Interactive Elements** - Hover effects and smooth transitions

## ğŸŒŸ Why Ambit AI?

| Traditional Assistants | Ambit AI |
|-------------------|---------------|
| âŒ Single voice option | âœ… 8+ voice personas |
| âŒ Fixed personality | âœ… Custom instructions |
| âŒ Basic interface | âœ… Interactive visualizer |
| âŒ Limited configuration | âœ… Full control |
| âŒ Echo issues | âœ… Professional WebRTC |

## ğŸ” Troubleshooting

### Connection Issues
- Ensure backend is running on port 8765
- Check WebSocket connection in browser console
- Verify API keys in `.env` file

### Audio Issues
- Allow microphone permissions in browser
- Check browser WebRTC support (Chrome/Edge recommended)
- Verify audio input device in system settings

### Voice Issues
- Confirm ElevenLabs API key is valid
- Check voice ID is correct
- Ensure sufficient API credits

## ğŸ“ Project Structure

```
AmbitChad/
â”œâ”€â”€ ambit_web_gui.html      # Enhanced web interface
â”œâ”€â”€ ambit_backend.py        # Unified backend server
â”œâ”€â”€ ambit_instructions.py   # AI personality base
â”œâ”€â”€ style.css              # Modern UI styling
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env.example          # Environment template
â”œâ”€â”€ .gitignore            # Git ignore file
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ faces/                # Facial recognition models
â””â”€â”€ tools/                # AI tool integrations
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ facial_recognition.py
    â””â”€â”€ registry.py
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Test with the web interface
5. Commit changes (`git commit -m 'Add amazing feature'`)
6. Push to branch (`git push origin feature/amazing-feature`)
7. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- OpenAI for GPT models
- ElevenLabs for voice synthesis and multiple voice personas
- WebRTC for professional audio processing
- Silero VAD for voice activity detection
- Modern web standards for cross-platform compatibility

## ğŸ“ Version History

### v2.0.0 (Latest)
- âœ¨ Enhanced audio visualizer with interactive feedback
- ğŸ¤ Added 8 preset voice personas
- ğŸ“ Custom instruction support
- ğŸ¨ Redesigned UI with glassmorphism
- âš™ï¸ Advanced settings panel
- ğŸ’¾ Persistent configuration storage

### v1.0.0
- ğŸš€ Initial release with basic voice assistant
- ğŸ¤ WebRTC audio support
- ğŸ¤– OpenAI integration
- ğŸ”Š ElevenLabs voice synthesis 